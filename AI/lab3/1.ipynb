{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports + Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "\n",
    "subscription_key = \"74e4096a2d984a61a75e1c640ba6e25e\"\n",
    "endpoint = \"https://ai-vision-andrei-diaconescu.cognitiveservices.azure.com/\"\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucces in resolvarea\n",
      "TEMELOR la\n",
      "LABORA toarele de\n",
      "Inteligenta ArtificialÃ !\n"
     ]
    }
   ],
   "source": [
    "# img = open(\"images/test1.png\", \"rb\")\n",
    "img = open(\"images/test2.jpeg\", \"rb\")\n",
    "read_response = computervision_client.read_in_stream(\n",
    "    image=img,\n",
    "    mode=\"Printed\",\n",
    "    raw=True\n",
    ")\n",
    "# print(read_response.as_dict())\n",
    "\n",
    "operation_id = read_response.headers['Operation-Location'].split('/')[-1]\n",
    "while True:\n",
    "    read_result = computervision_client.get_read_result(operation_id)\n",
    "    if read_result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "result = []\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            result.append(line.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluations\n",
      "LCS: 65\n",
      "Hamming: 32\n",
      "Levenshtein: 6\n",
      "Word Error Rate: 60.0\n",
      "Hamming Word: 7\n"
     ]
    }
   ],
   "source": [
    "def longest_common_subsequence(str1, str2):\n",
    "  dp = [[0 for _ in range(len(str2) + 1)] for _ in range(len(str1) + 1)]\n",
    "  for i in range(1, len(str1) + 1):\n",
    "    for j in range(1, len(str2) + 1):\n",
    "      if str1[i - 1] == str2[j - 1]:\n",
    "        dp[i][j] = 1 + dp[i - 1][j - 1]\n",
    "      else:\n",
    "        dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "  return dp[-1][-1]\n",
    "\n",
    "def hamming_dist(str1, str2):\n",
    "  cnt = 0\n",
    "  for i in range(min(len(str1), len(str2))):\n",
    "    if str1[i] != str2[i]:\n",
    "      cnt += 1\n",
    "  return cnt\n",
    "\n",
    "def hamming_word_dist(str1, str2):\n",
    "  cnt = 0\n",
    "  words_str1 = str1.split(' ')\n",
    "  words_str2 = str2.split(' ')\n",
    "  for i in range(min(len(words_str1), len(words_str2))):\n",
    "    if words_str1[i] != words_str2[i]:\n",
    "      cnt += 1\n",
    "  return cnt\n",
    "\n",
    "def levenshtein_dist(s1, s2):\n",
    "    matrix = [[0] * (len(s2) + 1) for _ in range(len(s1) + 1)]\n",
    "\n",
    "    for i in range(len(s1) + 1):\n",
    "        matrix[i][0] = i\n",
    "    for j in range(len(s2) + 1):\n",
    "        matrix[0][j] = j\n",
    "\n",
    "    for i in range(1, len(s1) + 1):\n",
    "        for j in range(1, len(s2) + 1):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            matrix[i][j] = min(matrix[i-1][j] + 1,    \n",
    "                               matrix[i][j-1] + 1,\n",
    "                               matrix[i-1][j-1] + cost)  \n",
    "\n",
    "    return matrix[len(s1)][len(s2)]  \n",
    "\n",
    "def wer_dist(ref, hyp):\n",
    "    ref_words = ref.split()\n",
    "    hyp_words = hyp.split()\n",
    "    \n",
    "    N = len(ref_words)\n",
    "    M = len(hyp_words)\n",
    "    dp = [[0] * (M + 1) for _ in range(N + 1)]\n",
    "    \n",
    "    for i in range(N + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(M + 1):\n",
    "        dp[0][j] = j\n",
    "    \n",
    "    for i in range(1, N + 1):\n",
    "        for j in range(1, M + 1):\n",
    "            if ref_words[i - 1] == hyp_words[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = min(dp[i - 1][j - 1], dp[i - 1][j], dp[i][j - 1]) + 1\n",
    "    \n",
    "    wer_value = dp[N][M] / len(ref_words) * 100\n",
    "    return wer_value \n",
    "\n",
    "\n",
    "\n",
    "# ground_truth = [\"Google Cloud\", \"Platform\"]\n",
    "ground_truth = [\"Succes in rezolvarea\", \"tEMELOR la\", \"LABORAtoaree de\", \"Inteligenta Artificiala!\"]\n",
    "\n",
    "lcs = longest_common_subsequence(\"\".join(result), \"\".join(ground_truth))\n",
    "hd = hamming_dist(\"\".join(result), \"\".join(ground_truth))\n",
    "ld = levenshtein_dist(\"\".join(result), \"\".join(ground_truth))\n",
    "wer = wer_dist(\" \".join(result), \" \".join(ground_truth))\n",
    "hd_word = hamming_word_dist(\" \".join(result), \" \".join(ground_truth))\n",
    "\n",
    "print(\"Evaluations\")\n",
    "print(\"LCS:\", lcs)\n",
    "print(\"Hamming:\", hd)\n",
    "print(\"Levenshtein:\", ld)\n",
    "print(\"Word Error Rate:\", wer)\n",
    "print(\"Hamming Word:\", hd_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Localisation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8190826249406705\n",
      "0.910353012093584\n",
      "0.8346515866007853\n",
      "0.5646560257362039\n"
     ]
    }
   ],
   "source": [
    "def aria_patrulaterului(puncte):\n",
    "\n",
    "    x1 = puncte[0]\n",
    "    y1 = puncte[1]\n",
    "    x2 = puncte[2]\n",
    "    y2 = puncte[3]\n",
    "    x3 = puncte[4]\n",
    "    y3 = puncte[5]\n",
    "    x4 = puncte[6]\n",
    "    y4 = puncte[7]\n",
    "    return abs((x1*y2 + x2*y3 + x3*y4 + x4*y1 - x2*y1 - x3*y2 - x4*y3 - x1*y4) / 2)\n",
    "\n",
    "def aria_intersectiei(patrulater1, patrulater2):\n",
    "    puncte_intersectie = [\n",
    "        max(patrulater1[0], patrulater2[0]),\n",
    "        max(patrulater1[1], patrulater2[1]),\n",
    "        \n",
    "        min(patrulater1[2], patrulater2[2]),\n",
    "        max(patrulater1[3], patrulater2[3]),\n",
    "        \n",
    "        min(patrulater1[4], patrulater2[4]),\n",
    "        min(patrulater1[5], patrulater2[5]),\n",
    "        \n",
    "        max(patrulater1[6], patrulater2[6]),\n",
    "        min(patrulater1[7], patrulater2[7])\n",
    "        \n",
    "    ]\n",
    "    aria_intersectiei = aria_patrulaterului(puncte_intersectie)\n",
    "    return aria_intersectiei\n",
    "\n",
    "def IoU(patrulater1, patrulater2):\n",
    "    aria1 = aria_patrulaterului(patrulater1)\n",
    "    aria2 = aria_patrulaterului(patrulater2)\n",
    "    intersectie = aria_intersectiei(patrulater1, patrulater2)\n",
    "    uniune = aria1 + aria2 - intersectie\n",
    "    \n",
    "    if uniune == 0:\n",
    "        return 0\n",
    "    \n",
    "    return intersectie / uniune\n",
    "\n",
    "\n",
    "# bounding_boxes_truth = [\n",
    "#     [177.0, 43.0, 414.0, 43.0, 414.0, 104.0, 177.0, 104.0],\n",
    "#     [237.0, 113.0, 347.0, 113.0, 347.0, 150.0, 237.0, 150.0]]\n",
    "\n",
    "bounding_boxes_truth = [\n",
    "  [79.0, 299.0, 1333.0, 299.0, 1333.0, 462.0, 79.0, 462.0],\n",
    "  [130.0, 580.0, 1045.0, 580.0, 1045.0, 722.0, 130.0, 722.0],\n",
    "  [82.0, 920.0, 998.0, 920.0, 998.0, 1026.0, 82.0, 1026.0],\n",
    "  [105.0, 1128.0, 1452.0, 1128.0, 1452.0, 1368.0, 105.0, 1368.0],\n",
    "  ]\n",
    "\n",
    "bound_boxes_detected = []\n",
    "for text_result in read_result.analyze_result.read_results:\n",
    "    for line in text_result.lines:\n",
    "        bound_boxes_detected.append(line.bounding_box)\n",
    "\n",
    "for i in range(len(bounding_boxes_truth)):\n",
    "    print(IoU(bounding_boxes_truth[i], bound_boxes_detected[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhancing the text recognition for test2.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "\n",
    "img = Image.open('images/test2.jpeg')\n",
    "\n",
    "img = img.convert('L')\n",
    "\n",
    "enhancer = ImageEnhance.Contrast(img)\n",
    "img = enhancer.enhance(2.0)\n",
    "\n",
    "threshold = 140\n",
    "img = img.point(lambda p: p > threshold and 255)\n",
    "\n",
    "img.save('images/test2_enhanced.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhancing the text recognition for test1.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "threshold = 170 \n",
    "\n",
    "def is_black_or_gray(r, g, b):\n",
    "    avg_intensity = (r + g + b) / 3\n",
    "    if avg_intensity < threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "image = Image.open('images/test1.png')\n",
    "\n",
    "image = image.convert('RGB')\n",
    "\n",
    "binarized_image = Image.new('1', image.size, 255) \n",
    "\n",
    "for x in range(image.width):\n",
    "    for y in range(image.height):\n",
    "        r, g, b = image.getpixel((x, y))\n",
    "        if is_black_or_gray(r, g, b):\n",
    "            binarized_image.putpixel((x, y), 0) \n",
    "\n",
    "# Save the binarized image\n",
    "binarized_image.save('images/test1_enhanced.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succes in resolvarea\n",
      "TEMELOR la\n",
      "LABORA toarele de\n",
      "Inteligenta ArtificialÃ !\n"
     ]
    }
   ],
   "source": [
    "# img = open(\"images/test1_enhanced.png\", \"rb\")\n",
    "img = open(\"images/test2_enhanced.jpeg\", \"rb\")\n",
    "\n",
    "read_response = computervision_client.read_in_stream(\n",
    "    image=img,\n",
    "    mode=\"Printed\",\n",
    "    raw=True\n",
    ")\n",
    "\n",
    "operation_id = read_response.headers['Operation-Location'].split('/')[-1]\n",
    "while True:\n",
    "    read_result = computervision_client.get_read_result(operation_id)\n",
    "    if read_result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "result = []\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            result.append(line.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
