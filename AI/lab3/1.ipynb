{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports + Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "\n",
    "subscription_key = \"74e4096a2d984a61a75e1c640ba6e25e\"\n",
    "endpoint = \"https://ai-vision-andrei-diaconescu.cognitiveservices.azure.com/\"\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucces in resolvarea\n",
      "TEMELOR la\n",
      "LABORA toarele de\n",
      "Inteligenta ArtificialÃ !\n"
     ]
    }
   ],
   "source": [
    "# img = open(\"images/test1.png\", \"rb\")\n",
    "img = open(\"images/test2.jpeg\", \"rb\")\n",
    "read_response = computervision_client.read_in_stream(\n",
    "    image=img,\n",
    "    mode=\"Printed\",\n",
    "    raw=True\n",
    ")\n",
    "# print(read_response.as_dict())\n",
    "\n",
    "operation_id = read_response.headers['Operation-Location'].split('/')[-1]\n",
    "while True:\n",
    "    read_result = computervision_client.get_read_result(operation_id)\n",
    "    if read_result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "result = []\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            result.append(line.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluations\n",
      "LCS: 20\n",
      "Hamming: 0\n",
      "Levenshtein: 0\n"
     ]
    }
   ],
   "source": [
    "def longest_common_subsequence(str1, str2):\n",
    "  dp = [[0 for _ in range(len(str2) + 1)] for _ in range(len(str1) + 1)]\n",
    "  for i in range(1, len(str1) + 1):\n",
    "    for j in range(1, len(str2) + 1):\n",
    "      if str1[i - 1] == str2[j - 1]:\n",
    "        dp[i][j] = 1 + dp[i - 1][j - 1]\n",
    "      else:\n",
    "        dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "  return dp[-1][-1]\n",
    "\n",
    "def hamming_dist(str1, str2):\n",
    "  cnt = 0\n",
    "  for i in range(min(len(str1), len(str2))):\n",
    "    if str1[i] != str2[i]:\n",
    "      cnt += 1\n",
    "  return cnt\n",
    "\n",
    "def levenshtein_dist(s1, s2):\n",
    "    matrix = [[0] * (len(s2) + 1) for _ in range(len(s1) + 1)]\n",
    "\n",
    "    for i in range(len(s1) + 1):\n",
    "        matrix[i][0] = i\n",
    "    for j in range(len(s2) + 1):\n",
    "        matrix[0][j] = j\n",
    "\n",
    "    for i in range(1, len(s1) + 1):\n",
    "        for j in range(1, len(s2) + 1):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            matrix[i][j] = min(matrix[i-1][j] + 1,    \n",
    "                               matrix[i][j-1] + 1,\n",
    "                               matrix[i-1][j-1] + cost)  \n",
    "\n",
    "    return matrix[len(s1)][len(s2)]   \n",
    "\n",
    "ground_truth = [\"Google Cloud\", \"Platform\"]\n",
    "# groundTruth = [\"Succes in rezolvarea\", \"tEMELOR la\", \"LABORAtoaree de\", \"Inteligenta Artificiala!\"]\n",
    "\n",
    "lcs = longest_common_subsequence(\"\".join(result), \"\".join(ground_truth))\n",
    "hd = hamming_dist(\"\".join(result), \"\".join(ground_truth))\n",
    "ld = levenshtein_dist(\"\".join(result), \"\".join(ground_truth))\n",
    "\n",
    "print(\"Evaluations\")\n",
    "print(\"LCS:\", lcs)\n",
    "print(\"Hamming:\", hd)\n",
    "print(\"Levenshtein:\", ld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Localisation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct bounding boxes: \n",
      "[[79.0, 299.0, 1333.0, 299.0, 1333.0, 462.0, 79.0, 462.0], [130.0, 580.0, 1045.0, 580.0, 1045.0, 722.0, 130.0, 722.0], [82.0, 920.0, 998.0, 920.0, 998.0, 1026.0, 82.0, 1026.0], [105.0, 1128.0, 1452.0, 1128.0, 1452.0, 1368.0, 105.0, 1368.0]]\n",
      "\n",
      "Detected bounding boxes: \n",
      "[[86.0, 314.0, 1335.0, 287.0, 1336.0, 443.0, 86.0, 478.0], [140.0, 590.0, 1045.0, 587.0, 1046.0, 723.0, 140.0, 727.0], [81.0, 915.0, 1007.0, 926.0, 1004.0, 1039.0, 78.0, 1014.0], [108.0, 1129.0, 1450.0, 1151.0, 1446.0, 1293.0, 105.0, 1259.0]]\n"
     ]
    }
   ],
   "source": [
    "# bounding_boxes_truth = [\n",
    "#     [177.0, 43.0, 414.0, 43.0, 414.0, 104.0, 177.0, 104.0],\n",
    "#     [237.0, 113.0, 347.0, 113.0, 347.0, 150.0, 237.0, 150.0]]\n",
    "\n",
    "bounding_boxes_truth = [\n",
    "  [79.0, 299.0, 1333.0, 299.0, 1333.0, 462.0, 79.0, 462.0],\n",
    "  [130.0, 580.0, 1045.0, 580.0, 1045.0, 722.0, 130.0, 722.0],\n",
    "  [82.0, 920.0, 998.0, 920.0, 998.0, 1026.0, 82.0, 1026.0],\n",
    "  [105.0, 1128.0, 1452.0, 1128.0, 1452.0, 1368.0, 105.0, 1368.0],\n",
    "  ]\n",
    "\n",
    "bound_boxes_detected = []\n",
    "for text_result in read_result.analyze_result.read_results:\n",
    "    for line in text_result.lines:\n",
    "        bound_boxes_detected.append(line.bounding_box)\n",
    "\n",
    "print(\"Correct bounding boxes: \")\n",
    "print(bounding_boxes_truth)\n",
    "\n",
    "print(\"\\nDetected bounding boxes: \")\n",
    "print(bound_boxes_detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhancing the text recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "\n",
    "img = Image.open('images/test1.png')\n",
    "\n",
    "img = img.convert('L')\n",
    "\n",
    "enhancer = ImageEnhance.Contrast(img)\n",
    "img = enhancer.enhance(2.0)\n",
    "\n",
    "threshold = 140\n",
    "img = img.point(lambda p: p > threshold and 255)\n",
    "\n",
    "img.save('images/test1_enhanced.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "threshold = 170 \n",
    "\n",
    "def is_black_or_gray(r, g, b):\n",
    "    avg_intensity = (r + g + b) / 3\n",
    "    if avg_intensity < threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "image = Image.open('images/test1.png')\n",
    "\n",
    "image = image.convert('RGB')\n",
    "\n",
    "binarized_image = Image.new('1', image.size, 255) \n",
    "\n",
    "for x in range(image.width):\n",
    "    for y in range(image.height):\n",
    "        r, g, b = image.getpixel((x, y))\n",
    "        if is_black_or_gray(r, g, b):\n",
    "            binarized_image.putpixel((x, y), 0) \n",
    "\n",
    "# Save the binarized image\n",
    "binarized_image.save('images/test1_enhanced.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Cloud\n",
      "Platform\n"
     ]
    }
   ],
   "source": [
    "img = open(\"images/test1_enhanced.png\", \"rb\")\n",
    "# img = open(\"images/test2_enhanced.jpeg\", \"rb\")\n",
    "\n",
    "read_response = computervision_client.read_in_stream(\n",
    "    image=img,\n",
    "    mode=\"Printed\",\n",
    "    raw=True\n",
    ")\n",
    "\n",
    "operation_id = read_response.headers['Operation-Location'].split('/')[-1]\n",
    "while True:\n",
    "    read_result = computervision_client.get_read_result(operation_id)\n",
    "    if read_result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "result = []\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            result.append(line.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
